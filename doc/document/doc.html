<!DOCTYPE html>
<html>
<head>
<title>doc.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
	font-size: 14px;
	padding: 0 12px;
	line-height: 22px;
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}


body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	color: #4080D0;
	text-decoration: none;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

h1 code,
h2 code,
h3 code,
h4 code,
h5 code,
h6 code {
	font-size: inherit;
	line-height: auto;
}

a:hover {
	color: #4080D0;
	text-decoration: underline;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left: 5px solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 14px;
	line-height: 19px;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

.mac code {
	font-size: 12px;
	line-height: 18px;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

/** Theming */

.vscode-light,
.vscode-light pre code {
	color: rgb(30, 30, 30);
}

.vscode-dark,
.vscode-dark pre code {
	color: #DDD;
}

.vscode-high-contrast,
.vscode-high-contrast pre code {
	color: white;
}

.vscode-light code {
	color: #A31515;
}

.vscode-dark code {
	color: #D7BA7D;
}

.vscode-light pre:not(.hljs),
.vscode-light code > div {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre:not(.hljs),
.vscode-dark code > div {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre:not(.hljs),
.vscode-high-contrast code > div {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

.vscode-light blockquote,
.vscode-dark blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.vscode-high-contrast blockquote {
	background: transparent;
	border-color: #fff;
}
</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family:  "Meiryo", "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

</head>
<body>
<h1 id="%E5%AE%9E%E9%AA%8C%E6%96%87%E6%A1%A3">实验文档</h1>
<h2 id="%E6%9C%80%E8%BF%91%E6%9B%B4%E6%96%B0%E6%97%B6%E9%97%B4%EF%BC%9A20190926">最近更新时间：2019.09.26</h2>
<p>[toc]</p>
<h2 id="1%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E6%A3%80%E6%B5%8Bdetection">1.恶意代码检测(detection)</h2>
<p>恶意代码检测的基本目的是给定可执行PE文件，判定其是否属于恶意代码，属于二分类问题，基线正确率为50%。</p>
<p>基本的实验方法包括<strong>基于特征提取+SVM/kNN</strong>、<strong>ResNet14</strong></p>
<h3 id="11-%E4%BD%BF%E7%94%A8%E4%BC%A0%E7%BB%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95">1.1 使用传统机器学习方法</h3>
<p>传统机器学习方法的基本思路是：首先利用领域或者专家知识提取PE文件中的特征，基于特征进行分类。
为了顺利的进行实验，模型的拟合不仅需要恶意代码特征样本，还需要良性代码文件作为反例同时
输入到模型中进行训练。本实验中的默认设定是从<strong>Windows</strong>中提取的可执行格式文件：</p>
<p><strong>exe</strong>,<strong>dll</strong>, <strong>ocx</strong>, <strong>sys</strong>, <strong>com</strong></p>
<p>同时为了与恶意文件的大小对齐，设定良性文件的大小范围为：</p>
<p><strong>15~3000 KB</strong></p>
<p>结果从Windows文件夹下提取到x个良性文件样本</p>
<h4 id="111-%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81%E6%96%B9%E6%B3%95">1.1.1 提取特征方法</h4>
<p>提取特征的方法参考了 [Transfer Learning for Image-Based Malware Classification&quot;,
Bhodia et.al(2019)](Transfer learning for image-based malware classification.pdf), 使用GitHub上的<a href="https://github.com/erocarrera/pefile">PeFile模块</a>。
其主要提取的是PE文件的<strong>代码特征</strong>，例如头文件大小SizeOfHeads，代码大小SizeOfCode，
SectionMeanEntropy模块平均熵等，总共54个特征作为分类时每个PE文件的特征向量。</p>
<p>通过观察，这些特征各个维度上的数据差距实质上较大。查看其中一个样本提取到的特征的值：</p>
<p><img src="../../modules/docFile/ml_rawdata_shape_view.PNG" alt="docFile/ml_rawdata_shape_view"></p>
<p>通过观察可以发现：</p>
<ul>
<li>
<p>特征内部的数据的尺度相差极大：例如代码段大小等数据就可能达到$10^{4}$的数量级，但是对于
例如MajorLinkerVersion主链接器版本等特征，其数量级仅仅在个位数上</p>
</li>
<li>
<p>某些特征的对于分类的贡献十分微小：例如第一个特征Machine，通过查看前100个样本的该值与label：</p>
</li>
</ul>
<p><img src="../../modules/docFile/ml_rawdata_firstdim_view.PNG" alt="docFile/ml_rawdata_firstdim_view"></p>
<p>可以发现该值大部分都是相同的332，同时少量不同值为34404的样本的标签并没有与其他值为332的标签有显著
不同，说明Machine特征对于分类的贡献十分微小。同时，Machine这类特征属于枚举类值，在值上样本间并不
会有较大的波动，因此该特征作为特征向量的一部分会造成数据中存在大量的冗余。</p>
<ul>
<li>数据的维度太高，降维前有54维，对于SVM，决策树等方法来说难以拟合</li>
</ul>
<h4 id="112-%E5%88%A9%E7%94%A8%E6%8F%90%E5%8F%96%E5%88%B0%E7%9A%84%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%E4%BC%A0%E7%BB%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%88%86%E7%B1%BB">1.1.2 利用提取到的特征进行传统机器学习的分类</h4>
<p>利用之前得到的数据可以直接输入到SVM，KNN等分类器中，其中k=1。利用PCA降维至2维得到
可视化结果。如果不对数据直接处理，得到的结果如下：</p>
<p><img src="../../modules/docFile/ml_raw_knn_plot.png" alt=""></p>
<p><img src="../../modules/docFile/ml_raw_knn_confmat.png" alt=""></p>
<p><img src="../../modules/docFile/ml_raw_svm_plot.png" alt=""></p>
<p><img src="../../modules/docFile/ml_raw_svm_confmat.png" alt=""></p>
<p>结果显示：</p>
<ul>
<li>
<p>kNN的分类正确率高达99%，这说明利用专家知识和领域知识构建的特征工程能够很好地在样本上发挥作用，使得恶意样本
和良性样本分离开，使得同类样本近邻。</p>
</li>
<li>
<p>SVM的正确只有50%，由于本实验本身为二分类，因此该结果说明SVM根本不能直接从数据中学习到任何的知识。初步分析
这是因为<strong>各维度之间数值尺度差距过大</strong>导致的。</p>
</li>
<li>
<p>在利用PCA降维时，查看了各特征值所占的比例，结果发现降维至n=2时，有一个特征值的值所占比例超过了99.99%，而占比第二大的特征值比例仅为$3*10^{-8}$。这说明分类几乎都是基于一个维度上的值进行分类的，实质上其他维度几乎没有分类效果，完全是冗余数据</p>
</li>
</ul>
<h4 id="113-%E6%A0%87%E5%87%86%E5%8C%96%E5%AF%B9%E4%BC%A0%E7%BB%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D">1.1.3 标准化对传统机器学习性能的影响</h4>
<p>因此考虑在读取数据时，对各数据维度进行标准化：</p>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">normalize_data</span><span class="hljs-params">(data)</span>:</span>
    mean = np.mean(data, axis=<span class="hljs-number">0</span>)

    std = np.std(data, axis=<span class="hljs-number">0</span>)
    normalize_func = <span class="hljs-keyword">lambda</span> x: (x - mean) / std
    data = np.apply_along_axis(normalize_func, axis=<span class="hljs-number">1</span>, arr=data)

    <span class="hljs-keyword">return</span> np.nan_to_num(data)
</div></code></pre>
<p>将标准化以后的数据重新输入到原模型中，其他设定不变，得到的结果如下：</p>
<p><img src="../../modules/docFile/ml_normal_knn_plot.png" alt=""></p>
<p><img src="../../modules/docFile/ml_normal_knn_confmat.png" alt=""></p>
<p><img src="../../modules/docFile/ml_normal_svm_plot.png" alt=""></p>
<p><img src="../../modules/docFile/ml_normal_svm_confmat.png" alt=""></p>
<p>可以发现经过标准化以后降维的使得分布更加直观，kNN的正确率几乎没有变化，但是SVM的正确直线上升，仅比kNN小1个百分点。</p>
<p><strong>需要注意的是，标准化是基于所有样本上进行的</strong>。因此，标准化所需的均值和标准差都是
基于训练集+测试集的数据进行的。然而在训练阶段使用测试阶段的数据违背了机器学习的基本
原则，因此在以后的传统机器学习实验中，<strong>均不对样本进行标准化</strong></p>
<h4 id="114-%E6%9F%90%E4%B8%AA%E5%A4%A7%E7%B1%BB%E7%9A%84%E6%A0%B7%E6%9C%AC%E7%BC%BA%E5%A4%B1%E6%97%B6%E5%AF%B9%E8%AF%A5%E7%B1%BB%E6%81%B6%E6%84%8F%E6%A0%B7%E6%9C%AC%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB">1.1.4 某个大类的样本缺失时对该类恶意样本进行分类</h4>
<p>考虑对于Virus，Trojan,Worm等大类的一个极限0-shot情况：训练样本中不包含这些大类的
样本，但是测试样本中的恶意代码样本均来自这些大类中。这种设定的目的是检验模型能否在没有见
过某种恶意代码的情况下将其识别出来，称“大类缺省实验”。在实验中，分别选择backdoor，email，
net-worm，trojan和virus作为缺省大类，分别使用不包含这些类的样本的其他类别的数据集训练kNN，
SVM等。同时，遵循1.1.3中阐述的原则，没有对特征进行标准化。训练时，同样使用相同数量的良性样本
同时输入到模型中，良性样本来自Windows。从恶意样本中抽样时，大致依然按照每个文件200个样本的规律。</p>
<p>Backdoor：
<img src="../../doc/ml_default_exp/backdoor/knn.png" alt="">
<img src="../../doc/ml_default_exp/backdoor/knn_confusion_matrix.png" alt="">
<img src="../../doc/ml_default_exp/backdoor/svm.png" alt="">
<img src="../../doc/ml_default_exp/backdoor/svm_confusion_matrix.png" alt=""></p>
<p>Email：
<img src="../../doc/ml_default_exp/email/knn.png" alt="">
<img src="../../doc/ml_default_exp/email/knn_confusion_matrix.png" alt="">
<img src="../../doc/ml_default_exp/email/svm.png" alt="">
<img src="../../doc/ml_default_exp/email/svm_confusion_matrix.png" alt=""></p>
<p>Net-Worm：
<img src="../../doc/ml_default_exp/net-worm/knn.png" alt="">
<img src="../../doc/ml_default_exp/net-worm/knn_confusion_matrix.png" alt="">
<img src="../../doc/ml_default_exp/net-worm/svm.png" alt="">
<img src="../../doc/ml_default_exp/net-worm/svm_confusion_matrix.png" alt=""></p>
<p>Trojan：
<img src="../../doc/ml_default_exp/trojan/knn.png" alt="">
<img src="../../doc/ml_default_exp/trojan/knn_confusion_matrix.png" alt="">
<img src="../../doc/ml_default_exp/trojan/svm.png" alt="">
<img src="../../doc/ml_default_exp/trojan/svm_confusion_matrix.png" alt=""></p>
<p>Virus:
<img src="../../doc/ml_default_exp/virus/knn.png" alt="">
<img src="../../doc/ml_default_exp/virus/knn_confusion_matrix.png" alt="">
<img src="../../doc/ml_default_exp/virus/svm.png" alt="">
<img src="../../doc/ml_default_exp/virus/svm_confusion_matrix.png" alt=""></p>
<p>由实验结果可见：</p>
<ul>
<li>
<p>kNN的正确率依然十分高，平均约97%，这说明恶意代码大类之间在代码特征上存在
相似性，使得能够没有见过某种大类。但是，考虑另外一种可能性，由于只使用了Windows
的良性样本作为正例，可能会因为良性样本的种类过于单一，使得模型只是学会了“分辨是否是
Windows样本”。因此，后续实验中应该考虑使用更多种类的良性样本</p>
</li>
<li>
<p>SVM的正确率依旧保持在接近5成左右，说明SVM确实对高维数据和数据间尺度差距过大难以
进行拟合。<strong>因此在后续实验中将不会再展示SVM的效果，只展示kNN的效果</strong></p>
</li>
</ul>
<h4 id="115-%E8%89%AF%E6%80%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E7%A6%BB%E7%9A%84%E5%A4%A7%E7%B1%BB%E7%BC%BA%E7%9C%81">1.1.5 良性数据集分离的大类缺省</h4>
<p>综合1.1.4中提出的可能性，因此考虑将训练时的良性数据集和测试时的良性数据集进行分离。
实验中又从C:/Program Files目录（该目录下大部分都是Windows工具程序或者驱动）下提
取了一定数量的良性样本，将Windows良性样本作为训练时的正例，将新的良性数据作为测试时
的正例，重新进行1.1.3的实验。结果如下（模型只使用了kNN）：</p>
<p>Backdoor：
<img src="../../doc/ml_default_test_split_exp/backdoor/knn.png" alt=""></p>
<p>Email：
<img src="../../doc/ml_default_test_split_exp/email/knn.png" alt=""></p>
<p>Net-Worm：
<img src="../../doc/ml_default_test_split_exp/net-worm/knn.png" alt=""></p>
<p>Trojan：
<img src="../../doc/ml_default_test_split_exp/trojan/knn.png" alt=""></p>
<p>Virus:
<img src="../../doc/ml_default_test_split_exp/virus/knn.png" alt=""></p>
<p>测试结果的混淆矩阵显示，恶意样本的识别几乎没有收到任何影响，正确率保持在96%~97%
左右；但是良性样本的识别正确率发生大幅度下降：从96%下降到75%左右，下滑了接近20%。
这说明不同背景的良性数据集确实存在差异，而且模型不能够很好地在这种差异上泛化。由于
良性样本的性能下降，使得模型整体的正确率下降了10%左右。</p>
<h4 id="116-%E5%AF%B9%E8%89%AF%E6%80%A7%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E6%80%9D%E8%80%83">1.1.6 对良性样本数据的思考</h4>
<p>如果要进行恶意代码的识别的话，为了适用在多种环境中，势必需要对各种良性样本都要有很好
的泛化。<strong>因此模型学习应该朝“样本是否是恶意样本”的方向进行</strong>：如果样本的特征接近恶意样本，
结果判定为恶意样本；如果样本在一定的间隔下不接近于恶意样本，则判定为良性样本。即模型
应该只识别恶意样本，不识别良性样本，这样的话应该就能对多种不同环境下的良性样本有更好的
泛化。</p>
<p>但是这个目标很难达到，能想到的唯一的办法就是增加良性样本的多样性，将多种环境下的良性样本输入
模型进行训练。但是问题的核心便落在了数据收集上。从这一点上来看，识别恶意代码的工作远比想象中
复杂得多。</p>
<h4 id="117-%E8%89%AF%E6%80%A7%E6%A0%B7%E6%9C%AC%E5%88%86%E7%A6%BB%E7%9A%84%E5%B0%8F%E6%A0%B7%E6%9C%AC%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E8%AF%86%E5%88%AB">1.1.7 良性样本分离的小样本恶意代码识别</h4>
<p>由于1.1.6中提到的良性数据集的多样性，因此后续对应的实验中都采取利用Windows数据集训练，
ProgramFiles中的文件进行测试的设定。同时，为了测定传统机器学习在小样本情境下的效果，
因此<strong>按大类分类，测定大类的小样本性能</strong>。实验一共进行了aworm，backdoor，net-worm，trojan
和virus 5个大类的测定。测试时测定了1-shot和5-shot两种小样本设定。结果如下（k=1）：</p>
<p>aworm：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/aworm/1-shot/1shot_all_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/aworm/5-shot/5shot_all_knn.png" alt=""></p>
<p>backdoor：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/backdoor/1-shot/1shot_all_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/backdoor/5-shot/5shot_all_knn.png" alt=""></p>
<p>net-worm：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/net-worm/1-shot/1shot_all_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/net-worm/5-shot/5shot_all_knn.png" alt="缺失"></p>
<p>trojan：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/trojan/1-shot/1shot_all_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/trojan/5-shot/5shot_all_knn.png" alt=""></p>
<p>virus：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/virus/1-shot/1shot_all_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/virus/5-shot/5shot_all_knn.png" alt=""></p>
<p>可以发现：</p>
<ul>
<li>
<p>由于样本的采样情况各不相同，导致具有代表性的点和异常点的采样分布不均，因此
5-shot的性能不一定大于1-shot的性能</p>
</li>
<li>
<p>恶意样本的分类正确率明显高于良性样本的分类正确率。这说明恶意样本的分布在该
特征下较为集中，但是良性样本的多样性导致用Windows数据集训练的分类器在小样本
的设定下更加难以泛化到其他良性数据上</p>
</li>
<li>
<p>正确率普遍偏低，二分类的基础正确率有50%，但是大部分的最终正确率都在70%~80%
之间</p>
</li>
</ul>
<p>在大类缺省的基础上，进一步进行了小类缺省的小样本实验，即：训练数据中不包含小类的数据，
如aworm.Win32.AutoRun。其余与上一个实验设定基本相同，结果如下：</p>
<p>aworm.AutoRun：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/aworm/1-shot/1shot_AutoRun_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/aworm/5-shot/5shot_AutoRun_knn.png" alt=""></p>
<p>backdoor.Agent：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/backdoor/1-shot/1shot_Agent_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/backdoor/5-shot/5shot_Agent_knn.png" alt=""></p>
<p>backdoor.IRCBot：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/backdoor/1-shot/1shot_IRCBot_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/backdoor/5-shot/5shot_IRCBot_knn.png" alt=""></p>
<p>backdoor.PcClient：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/backdoor/1-shot/1shot_PcClient_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/backdoor/5-shot/5shot_PcClient_knn.png" alt=""></p>
<p>net-worm.Renos：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/net-worm/1-shot/1shot_Renos_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/net-worm/5-shot/5shot_Renos_knn.png" alt=""></p>
<p>trojan.Banker：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/trojan/1-shot/1shot_Banker_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/trojan/5-shot/5shot_Banker_knn.png" alt=""></p>
<p>trojan.LdPinch：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/trojan/1-shot/1shot_LdPinch_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/trojan/5-shot/5shot_LdPinch_knn.png" alt=""></p>
<p>trojan.OnLineGames：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/trojan/1-shot/1shot_OnLineGames_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/trojan/5-shot/5shot_OnLineGames_knn.png" alt=""></p>
<p>trojan.Pakes：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/trojan/1-shot/1shot_Pakes_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/trojan/5-shot/5shot_Pakes_knn.png" alt=""></p>
<p>trojan.VB：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/trojan/1-shot/1shot_VB_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/trojan/5-shot/5shot_VB_knn.png" alt=""></p>
<p>trojan.Zlob：</p>
<p>1-shot:
<img src="../../doc/ml_fewshot_exp/trojan/1-shot/1shot_Zlob_knn.png" alt=""></p>
<p>5-shot:
<img src="../../doc/ml_fewshot_exp/trojan/5-shot/5shot_Zlob_knn.png" alt=""></p>
<p>由于采样等问题，上述数据表现的正确率等都有较大程度的波动。但是大部分的正确率都位于
70~80%之间。这说明实质上，由于特征提取的性质，导致虽然良性样本与恶意样本分隔了较大
的间隔，但是恶意样本之间实质上并没有很好的分开，即：<strong>基于代码特征的机器学习方法不能</strong>
<strong>很好将恶意代码分类(classification)，但是能够很好进行恶意代码的识别(detection)</strong></p>
<h3 id="12-%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95">1.2 使用深度学习方法</h3>
<p>深度学习方法主要是将数据向量化后输入到深度神经网络中得到预测的输出值。本实验中将PE文件
转换为灰度图像的方法参考自 <a href="Malware%20Image%20Visualization%20and%20Automatic%20Classification.pdf">Natara et.al(2011)</a>
。但是该论文中的将PE文件转换为灰度图像的方法是：对于不同长度PE文件应用不同的固定宽度，
图像的长度是可变的。文件大小与宽度的关系如下：</p>
<table>
<thead>
<tr>
<th>大小范围</th>
<th>宽度</th>
</tr>
</thead>
<tbody>
<tr>
<td>&lt;10KB</td>
<td>32</td>
</tr>
<tr>
<td>10-30KB</td>
<td>64</td>
</tr>
<tr>
<td>30-60KB</td>
<td>128</td>
</tr>
<tr>
<td>60-100KB</td>
<td>256</td>
</tr>
<tr>
<td>100-200KB</td>
<td>384</td>
</tr>
<tr>
<td>200-500KB</td>
<td>512</td>
</tr>
<tr>
<td>500-100KB</td>
<td>768</td>
</tr>
<tr>
<td>&gt;1000KB</td>
<td>1024</td>
</tr>
</tbody>
</table>
<p>该论文中使用了GIST特征对图像进行小波分解以提取图像的纹理特征，然后将提取的特征输入到欧式
距离的kNN进行分类。参考这种方法，后续有很多实验围绕恶意代码图像进行：</p>
<p><a href="Convolutional%20Neural%20Networks%20for%20Malware%20Classification.pdf">Gibert(2016)</a>
使用简单的卷积神经网络进行分类和识别。不仅使用了图像，还使用了微软数据集中提供的反汇编代码
提取Opcode操作码进行分类。</p>
<p><a href="Image-Based%20Malware%20Classification%20Using.pdf">Kim(2018)</a>
同样使用的是Conv+FC的经典组合。</p>
<p><a href="Malware%20Classification%20with%20Deep%20CNN.pdf">Kalash et.al(2018)</a>
基于VGG-16搭建深度卷积网络+softmax分类器进行分类，同时还改用SVM对GIST特征进行分类
来搭建基线。</p>
<p><a href="Malware%20Detection%20using%20Malware%20Image%20and%20Deep%20Learning.pdf">Choi et.al(2017)</a>
使用相似的方式转换图像后，输入到Conv+FC中进行分类。与之前不同的是，论文作者采用固定的256x256
的图像尺寸，该尺寸下的代码大小为固定的64KB。对于大于64KB的文件，之后的部分直接丢弃；对于小于
64KB的图像，将会填充0。文章中作者为了减小显存消耗，还将图片通过下采样将尺寸调整为32x32。</p>
<h4 id="121-%E4%BD%BF%E7%94%A8resnet%E8%BF%9B%E8%A1%8C%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E6%A3%80%E6%B5%8B">1.2.1 使用ResNet进行恶意代码检测</h4>
<p>根据论文[Transfer Learning for Image-Based Malware Classification&quot;,
Bhodia et.al(2019)](Transfer learning for image-based malware classification.pdf)
中的描述，他们使用了ResNet34作为恶意代码检测的模型架构。该论文中使用的恶意代码数据集是Malimg
和Malicia两个，而训练使用的良性数据集提取了3304个Windows文件。该论文中的网络是经过ImageNet
数据集预训练的，同时使用了多种技术，如余弦退火cosine annealing，带重启的梯度下降gradient descent
with restart，学习率搜索等。同时使用fast.ai进行实现。该论文中进行了一个十分类似0-shot的实验：
论文中称之为zero day setting，即使用Malimg数据集进行训练，而使用Malicia数据集进行测试。
除此之外，文章对恶意代码识别和恶意代码分类均有涉猎，值得参考。</p>
<h5 id="1211-%E5%B0%86pe%E6%96%87%E4%BB%B6%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E5%9B%BE%E5%83%8F">1.2.1.1 将PE文件转换为恶意代码图像</h5>
<p>由于ResNet中要具有分类效果的话需要加入FC层，因此图像只能是固定大小尺寸作为输入。规定图像尺寸为256x256，
为了让不同长度的文件都生成相同尺寸的图像，其具体步骤如下：</p>
<ol>
<li>
<p>仿照论文中的方式，每8bit将二进制文件处理为0-255的一个灰度值，生成长度为L的灰度序列</p>
</li>
<li>
<p>将序列转换为正方形形状的图像。</p>
<p>先求正方形图像的边长： $\hat{L} = \lfloor\sqrt{L}\rfloor$</p>
<p>再取原图像的前$L^2$个灰度值，整理为$\hat{L}\times\hat{L}$的正方形图像</p>
</li>
<li>
<p>$\hat{L} &gt; 256$时，通过scale将图像调整为256x256的图像；$\hat{L} &lt; 256$ 时，通过插值放大
调整为256x256</p>
</li>
</ol>
<p>生成图像时，利用了PIL库中的Image.ANTIALIAS方法进行缩放处理：</p>
<pre class="hljs"><code><div>        crop_w = int(image.shape[<span class="hljs-number">0</span>] ** <span class="hljs-number">0.5</span>)
        image = image[:crop_w ** <span class="hljs-number">2</span>]
        image = image.reshape((crop_w, crop_w))
        image = np.uint8(image)
        <span class="hljs-keyword">if</span> padding <span class="hljs-keyword">and</span> crop_w &lt; WIDTH:
            image = np.pad(image, (WIDTH - crop_w), <span class="hljs-string">'constant'</span>, constant_values=(<span class="hljs-number">0</span>))
        im = Image.fromarray(image)
        <span class="hljs-keyword">if</span> fuzzy <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            im = im.resize((fuzzy, fuzzy), Image.ANTIALIAS)
        im = im.resize((WIDTH, WIDTH), Image.ANTIALIAS)
</div></code></pre>
<p>这种方法能够得到同一尺寸的图像，通过观察可以看到同一个类中的一些图像确实具有相似的纹理和可视特征，
例如:</p>
<p><img src="" alt="图像。。。"></p>
<p>但是相应的，由于scale会使得图像细节变得模糊，甚至失真，因此即使是某些同类图像也难以直接识别
其是否具有相似的特征。</p>
<p>由于恶意代码图像的缩放和插值处理，同时加上其本身的纹理和特征不具有直观性，因此人类无法直接
通过恶意代码图像直接进行分类。因此，<strong>该识别任务难以进行直观的可视化观测</strong>，同时该任务在性
能上的表现一定会超越人类。</p>
<h5 id="1212-%E8%AE%AD%E7%BB%83%E9%9B%86%E5%88%86%E7%A6%BB%E7%9A%84resnet%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E6%A3%80%E6%B5%8B">1.2.1.2 训练集分离的ResNet恶意代码检测</h5>
<p>遵循之前传统机器学习中的设定：训练集中良性数据集使用Windows数据集，而测试中的良性数据集使用
ProgramFiles的数据集。训练时，按照之前的设定，每一个恶意代码的文件夹都抽取100个样本，共13
个文件夹生成1300个恶意代码的训练样本，同时从Windows中抽取等同数量的良性样本，混合后输入
到ResNet进行训练，训练曲线如下：</p>
<p><img src="../../doc/dl_whole_exp/acc.png" alt=""></p>
<p><img src="../../doc/dl_whole_exp/loss.png" alt=""></p>
<p><img src="../../doc/dl_whole_exp/confusion_matrix.png" alt=""></p>
<p>显然，由于训练集的分离，使得模型对于良性数据过拟合，而对于恶意代码样本的具有很好的拟合，这
与传统机器学习中的情况相同。同时，模型整体的正确率也显著低于传统机器学习方法。这说明，从
图像上直接提取特征，ResNet的性能很难超越传统机器学习方法。</p>
<h5 id="1213-%E8%AE%AD%E7%BB%83%E9%9B%86%E5%88%86%E7%A6%BB%E7%9A%84resnet%E5%A4%A7%E7%B1%BB%E7%BC%BA%E7%9C%81%E7%9A%84%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E6%A3%80%E6%B5%8B">1.2.1.3 训练集分离的ResNet大类缺省的恶意代码检测</h5>
<p>相同的设定，不同的是训练数据中不包含某些大类的数据，然后测试中的恶意代码是来自这些缺少的大类
以此来模拟0-shot的情景：ResNet是否能在没有见过某些数据的情况下对其进行准确分类，是否能提取
到具有良好泛化性的特征。同时，这种测试情景模拟了<a href="Transfer%20learning%20for%20image-based%20malware%20classification.pdf">Bhodia et.al(2019)</a>
中zero-day的实验设定。</p>
<p>测试结果如下：</p>
<p>backdoor缺省：
<img src="../../doc/dl_default_exp/backdoor_default_acc.png" alt=""></p>
<p><img src="../../doc/dl_default_exp/backdoor_default_loss.png" alt=""></p>
<p><img src="../../doc/dl_default_exp/backdoor_cf.png" alt=""></p>
<p>trojan缺省：
<img src="../../doc/dl_default_exp/trojan_default_acc.png" alt=""></p>
<p><img src="../../doc/dl_default_exp/trojan_default_loss.png" alt=""></p>
<p><img src="../../doc/dl_default_exp/trojan_cf.png" alt=""></p>
<p>virus缺省：
<img src="../../doc/dl_default_exp/virus_default_acc.png" alt=""></p>
<p><img src="../../doc/dl_default_exp/virus_default_loss.png" alt=""></p>
<p><img src="../../doc/dl_default_exp/virus_cf.png" alt=""></p>
<p>与非大类缺省的情况相似，模型在恶意代码上几乎没有出现过拟合现象，分类正确率高达97%左右；
性能瓶颈主要是位于良性数据集上。同时，可以从学习曲线中发现在训练过程中过拟合几乎从训练开始
就出现了，而且随着训练过程进行越来越严重。</p>
<h5 id="1214-%E5%88%A9%E7%94%A8%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AF%B9%E7%BC%BA%E7%9C%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8Cfine-tuning">1.2.1.4 利用小样本对缺省训练模型进行fine-tuning</h5>
<p>由于ResNet此类的深度卷积网络在数据集少时会遭受严重的过拟合，在没有特殊训练方式的支持下
不能直接使用小样本数据进行从头学习。在小样本学习领域的一个普遍的方法是：在其他数据集上进行
预训练，然后利用小样本数据对预训练好的模型进行权重微调fine-tuning。这样使得模型对没见过的
novel class</p>
<p>为了进行该实验，首先在某个大类X缺省的数据集上训练模型，然后利用小样本的X（5-shot）对训练得到
的模型进行微调。选取X=backdoor，trojan和virus三个大类。微调时，为了避免对恶意代码产生
过大的偏置，因此微调的数据集中添加了同等数量的Windows良性样本。</p>
<p>实验结果如下：</p>
<p>backdoor缺省：
<img src="../../doc/dl_default_retrain_fewshot_exp/backdoor_default/before_cm.png" alt=""></p>
<p><img src="../../doc/dl_default_retrain_fewshot_exp/backdoor_default/after_cm.png" alt=""></p>
<p>trojan缺省：
<img src="../../doc/dl_default_retrain_fewshot_exp/trojan_default/before_cm.png" alt=""></p>
<p><img src="../../doc/dl_default_retrain_fewshot_exp/trojan_default/after_cm.png" alt=""></p>
<p>virus缺省：
<img src="../../doc/dl_default_retrain_fewshot_exp/virus_default/before_cm.png" alt=""></p>
<p><img src="../../doc/dl_default_retrain_fewshot_exp/virus_default/after_cm.png" alt=""></p>
<p>可以看到微调并没有对整体正确率有显著的提升：</p>
<ol>
<li>
<p>5-shot用于微调的数据并不能保证具有该类的代表性，因此可能对缺省的类进行分类时其提升效果
并不能被保证</p>
</li>
<li>
<p>微调时由于缺少原训练集中的数据，因此会<strong>导致对原数据集产生遗忘</strong></p>
</li>
<li>
<p>由于没有加入测试集中的分离的良性数据，因此良性数据的分类效果几乎没有提升</p>
</li>
</ol>
<p>因此，如果原训练模型没有很好的结构，或者原模型的训练方式没有很好的定制，或者微调的方式没有
很好的制定，则小样本的微调并不能解决数据适应的问题。</p>
<h5 id="1215-%E5%B0%9D%E8%AF%95%E5%88%A9%E7%94%A8%E5%99%AA%E5%A3%B0%E5%9B%BE%E5%83%8F%E6%9D%A5%E6%8F%90%E9%AB%98%E8%AE%AD%E7%BB%83%E9%9B%86%E5%88%86%E7%A6%BB%E6%97%B6%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96%E6%80%A7">1.2.1.5 尝试利用噪声图像来提高训练集分离时的模型泛化性</h5>
<p>在实际应用情景中，我们希望在各种情况下，即遇到不同来源的良性数据集时，模型都能将其与
恶意代码分类开。换句话说，我们希望模型对数据进行“识别其是否是恶意代码，如果不是那就是
良性代码”的任务，即只对恶意代码敏感，而对非恶意代码不敏感。如果模型能够学习到这样的
识别能力，那么只要该代码不含有恶意代码的特征，无论其来自什么数据集或者应用场景中，模型
都能对其进行正确分类。</p>
<p>但是由于模型的训练是基于数据的，除非特殊设计，模型很难对这种能力进行学习。为了达到
这种目的，必须要使良性数据集具有足够大的多样性，同时其不具有恶意代码的特征。首先能够
想到的方式就是<strong>人为生产一定数量的噪声图像输入到模型中作为良性数据集的增补</strong>。</p>
<p>生成噪声的方式主要有均匀噪声，高斯噪声和恒值噪声等。本实验中主要使用高斯噪声，即每个点
的灰度值独立地服从高斯分布，实验中点的采样服从:</p>
<p>$f(x,y) \sim N(128,40)$</p>
<p>正态分布的分布特征：3个标准差内的密度值高达99.9%，以来保证大部分的值位于[0,255]之间，同时大部分的值位于均值附近。</p>
<p>训练时，在训练集中混入良性数据集中Windows文件数量一半数量的噪声图像以帮助训练。同时
训练的基础设定为大类缺省。因此，将在大类缺省的情况下测试噪声加入后的泛化效果。</p>
<p>实验结果显示，噪声并不能加强模型的泛化能力，反而使得模型难以收敛。因此实验只进行了一
部分：</p>
<p><img src="../../doc/dl_noisebenign_default_exp/backdoor_default/backdoor_default_acc.png" alt=""></p>
<p><img src="../../doc/dl_noisebenign_default_exp/backdoor_default/backdoor_default_loss.png" alt=""></p>
<p><img src="../../doc/dl_noisebenign_default_exp/backdoor_default/half_noise_cm.png" alt=""></p>
<h2 id="2%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E5%88%86%E7%B1%BB">2.恶意代码分类</h2>
<p>恶意代码分类是指给定某几个类（大类或者小类）的样本，要求训练器能够将同属于这些类的样本进行分类。恶意代码
的大类一般定义为其根类别，如Virus，Trojan，Aworm，DOS等；而小类的定义一般是根据给定的文件的命名方式
而定，一般文件名取按&quot;.&quot;划分以后的前三个字段。</p>
<p>例如：
Backdoor.Win32.Hupigon.zah 位于backdoor文件夹中，因此其大类为backdoor；其由&quot;.&quot;划分的字段的前三
个元素为Backdoor.Win32.Hupigon，因此其小类就对应这个名字。提取其小类名称的代码段如下：</p>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract_class_name</span><span class="hljs-params">(name)</span>:</span>
    <span class="hljs-keyword">return</span> <span class="hljs-string">'.'</span>.join(name.split(<span class="hljs-string">'.'</span>)[:<span class="hljs-number">3</span>])
</div></code></pre>

</body>
</html>
