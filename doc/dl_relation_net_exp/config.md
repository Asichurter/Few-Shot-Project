# 运行描述

## 第1次运行

相比于之前的模型：

1. 增加了卷积核的数量

2. 将BN层的动量系数从1改为了默认值

3. 由于Bn层的效果会导致偏置失效，因此取消了所有卷积的偏置

4. 通过添加stride=2，关系网络中的卷积层将会把特征最后卷积为1x1的特征大小

5. 使用的是modified修改后的数据集采样器
                        
6. 30个训练类，5个验证类，每个类均只有20个样本

---

## 第2次运行

1. 考虑到出现了过拟合，因此使用修正前的随机抽样的采样器来采样。方式是：只在训练的时候使用modified采样器，
但是在测试时使用固定的采样器

---

## 第3次运行

1. 在线性连接层之间增加了dropout，设置为p=0.5

--- 

## 第4次运行

1. 取消dropout和随机抽样

2. 减小初始学习率至5e-4

---

## 第5次运行

1. 将优化器由嵌入和关系网络分开改为合二为一

2. 将隐藏层的宽度由64提高到256

---

## 第6次运行（未进行）

1. 在两个全连接层之间添加了批标准化BN层

2. 将全连接层的隐藏层的维度改回64

---

## 第6次运行

1. 修改了关系网络中的每个卷积层的卷积核数量，使得每一个层的卷积核数量都为512，至少不会在前馈的时候卷积核
数量减少

2. 将隐藏层的节点数量降至8

3. 将嵌入网络的卷积核大小均改为3x3

--- 

## 第7次运行(不小心把第6次覆盖了)

1. 修正了支持集和查询集嵌入后，repeat使用不当导致的错位，但是效果不一定更好（？）

2. 训练集的规模扩张至60个class

## 真·第7次运行

1. 修改了初始化方式

2. 恢复了嵌入后的数据处理，因为是正确的

3. 调整Adam的初始学习率为1e-3

4. 恢复了原论文中的卷积核数量，但是为了将尺寸减小到较小的尺寸上，嵌入层
所有的卷积都附加了最大池化,同时经过试验，如果不在第一层加stride的话，
会爆显存，因此只在第一层以后加stride

## 进一步的探索可能：

1. 进一步减小初始学习率

2. 增大全连接层的宽度和深度

3. 改用带动量和逐步减小学习率的SGD代替Adam

4. 改用平均池化代替最大池化

5. 嵌入层初始层中卷积核的尺寸改回3