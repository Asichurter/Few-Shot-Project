# 运行描述

## 第1次运行

相比于之前的模型：

1. 增加了卷积核的数量

2. 将BN层的动量系数从1改为了默认值

3. 由于Bn层的效果会导致偏置失效，因此取消了所有卷积的偏置

4. 通过添加stride=2，关系网络中的卷积层将会把特征最后卷积为1x1的特征大小

5. 使用的是modified修改后的数据集采样器
                        
6. 30个训练类，5个验证类，每个类均只有20个样本

---

## 第2次运行

1. 考虑到出现了过拟合，因此使用修正前的随机抽样的采样器来采样。方式是：只在训练的时候使用modified采样器，
但是在测试时使用固定的采样器

---

## 第3次运行

1. 在线性连接层之间增加了dropout，设置为p=0.5

--- 

## 第4次运行

1. 取消dropout和随机抽样

2. 减小初始学习率至5e-4

---

## 第5次运行

1. 将优化器由嵌入和关系网络分开改为合二为一

2. 将隐藏层的宽度由64提高到256

---

## 第6次运行（未进行）

1. 在两个全连接层之间添加了批标准化BN层

2. 将全连接层的隐藏层的维度改回64

---

## 第6次运行

1. 修改了关系网络中的每个卷积层的卷积核数量，使得每一个层的卷积核数量都为512，至少不会在前馈的时候卷积核
数量减少

2. 将隐藏层的节点数量降至8

3. 将嵌入网络的卷积核大小均改为3x3

--- 

## 第7次运行(不小心把第6次覆盖了)

1. 修正了支持集和查询集嵌入后，repeat使用不当导致的错位，但是效果不一定更好（？）

2. 训练集的规模扩张至60个class

## 真·第7次运行

1. 修改了初始化方式

2. 恢复了嵌入后的数据处理，因为是正确的

3. 调整Adam的初始学习率为1e-3

4. 恢复了原论文中的卷积核数量，但是为了将尺寸减小到较小的尺寸上，嵌入层
所有的卷积都附加了最大池化,同时经过试验，如果不在第一层加stride的话，
会爆显存，因此只在第一层以后加stride

5. 扩增了数据集规模以对抗过拟合，训练集300个数据集，测试集111个数据集

---

## 第8次运行

1. 减少了可用的训练集数量：从300减到150。
因为增大训练集的规模似乎会使模型学习过于震荡且无法收敛（表示能力的关系？）

2. 修改初始化方式为论文中的方式

---

## 第9次运行

1. 减少了训练集和测试集的规模：训练集为60，测试集为30

---

## 第10次运行

1. 修改了网络结构：关系模块的卷积层中加入了stride使得卷积输出为1x1图像，
同时删去了隐藏层，直接通过一个全连接层输出维度为1的值

2. 将关系网络中的最大池化改为了平均池化

---

## 第11次运行

1. 将平均池化改为最大池化

2. 将训练集规模缩小至30

---

## 第12次运行

1. 重新加入了fc2

2. 将两个卷积结果连接的方式由按深度相加改为按深度相减

## 第13次运行

1. 使用了修正的数据集，采样的方法也从固定的前k个改为随机类内采样，使用了224x224的裁剪

2. 适当地改变了网络结构以适应224的尺寸：取消了relation模块的stride，需手动输入embed_size

## 15

1. 5-shot 5-way

## 16

1. 5-shot 20-way

## 17

1. 10-shot 5-way

## 18

1. 10-shot 20-way

## 19

1. virushare_20 数据集

2. 5-shot 20-way

## 20

1. virushare_20 数据集

2. 5-shot 20-way

## 21

1. virushare_20数据集

2. 10-shot 5-way

## 22

1. virushare_20数据集

2. 5-shot 5-way

## 23

1. virushare_20数据集

2. 10-shot 20-way    

## 24

1. test数据集

2. 5-shot 5-way


---

## 进一步的探索可能：

1. 进一步减小初始学习率

2. 增大全连接层的宽度和深度

3. 改用带动量和逐步减小学习率的SGD代替Adam

4. 改用平均池化代替最大池化

5. 嵌入层初始层中卷积核的尺寸改回3

6. 打印输出的relation

7. 可视化中间层卷积核的权重

8. 打乱相同的sample set的顺序，查看对于相同的query set是否有影响

9. 提取中间层输出，对比不同的class的输入其中间层的值的差异分析

10. 考虑fine-tuning：只微调relation部分，锁定embed部分

11. 不将类样本的平均代表类，而是类中的每个样本都参与比较

12. 类中样本组合成类向量的时候，考虑使用一个子网络来组合

